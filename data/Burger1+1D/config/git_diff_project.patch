diff --git a/include/neural_net.py b/include/neural_net.py
index 9dc90b6..a12d583 100644
--- a/include/neural_net.py
+++ b/include/neural_net.py
@@ -142,14 +142,6 @@ class NeuralNet(nn.Module):
         # Get the optimizer
         self.optimizer = self.OPTIMIZERS[optimizer](self.parameters(), lr=learning_rate)

-        # Initialize the loss tracker dictionary, which can be used to later evaluate the training progress
-        self._loss_tracker: dict = {
-            "iter": [],
-            "total_loss": [],
-            "loss_b": [],
-            "loss_v": [],
-        }
-
         # Get equation type and variational form
         self._eq_type = eq_type
         self._var_form = var_form
diff --git a/model/cfgs/Burger1+1D/eval.yml b/model/cfgs/Burger1+1D/eval.yml
index cb18c49..3c357cb 100644
--- a/model/cfgs/Burger1+1D/eval.yml
+++ b/model/cfgs/Burger1+1D/eval.yml
@@ -24,7 +24,7 @@ frames:
     data:
       path: VPINN/predictions
       transform:
-        - .isel: [!dag_prev , {y: !slice [~, ~, 32]}]
+        - .isel: [!dag_prev , {y: !slice [~, ~, 33]}]
   col: y
 loss:
   based_on: loss
@@ -43,7 +43,7 @@ boundary_conditions:
     - .creator.universe
     - .plot.facet_grid.scatter
   select:
-    vals: data/u_exact_boundary
+    vals: data/training_data
   transform:
     - .sel: [!dag_tag vals , {'variable': 'x'}]
       kwargs:
diff --git a/model/cfgs/Burger1+1D/run.yml b/model/cfgs/Burger1+1D/run.yml
index eb2625c..0ff733d 100644
--- a/model/cfgs/Burger1+1D/run.yml
+++ b/model/cfgs/Burger1+1D/run.yml
@@ -2,14 +2,14 @@
 paths:
   model_note: Burger1+1D
 parameter_space:
-  num_epochs: 10000
+  num_epochs: 1
   VPINN:
     space:
       x:
         extent: [-2, 4]
         size: 300
       y:
-        extent: [0, 2]
+        extent: [0.1, 2]
         size: 80
     PDE:
       function: Burger1+1D
@@ -20,14 +20,13 @@ parameter_space:
         n_x:
           size: 15
         n_y:
-          size: 10
-      weight_function: exponential
+          size: 8
+      weight_function: uniform
     NeuralNet:
-      num_layers: 2
+      num_layers: 1
+      nodes_per_layer: 2
       activation_funcs:
         0: relu
-        1: relu
-        -1: None
     variational_form: 1
     Training:
       boundary: lower
