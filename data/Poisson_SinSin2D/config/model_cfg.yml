---
# Data loading .........................................................................................................
load_data:
  data_dir: ~ # folder containing the .h5 file
  copy_data: False # Whether to copy the loaded data to the new directory
  print_tree: False # other parameters here will be passed to utopya.eval.DataManager.load

# Domain settings ......................................................................................................
space:
  x:
    extent: [-1, 1]
    size: 20

# PDE parameters .......................................................................................................
PDE:
  # Type of equation
  type: !param
    default: Burger
    dtype: str
    is_any_of: [Poisson, Burger]
  # External function example
  function: !param
    default: Tanh
    dtype: str
    is_any_of: [Tanh, Tanh2D, SinSin2D, Burger1+1D, DoubleGauss1D, CubedRoot, PorousMedium]
  # Scalar parameters for the equations
  PorousMedium:
    m: 2
  Helmholtz:
    k: -2.5
  Burger:
    nu: !is-positive-or-zero 0

# The variational form to use; can be 0, 1, or 2
variational_form: !param
  default: 1
  is_any_of: [0, 1, 2]

# Test function settings ...............................................................................................
test_functions:
  num_functions:
    n_x:
      size: 3
  type: !param
    default: Legendre
    dtype: str
    is_any_of: [Legendre, Chebyshev, Sine]

  # The type of weighting to use
  weight_function: !param
    default: exponential
    is_any_of: [uniform, exponential]


# Neural net architecture ..............................................................................................
NeuralNet:
  num_layers: !is-positive-int 4
  nodes_per_layer: !is-positive-int 20
  activation_funcs: tanh
  optimizer: !param
    default: Adam
    is_any_of: [Adagrad, Adam, AdamW, SparseAdam, Adamax, ASGD, LBFGS, NAdam, RAdam, RMSprop, Rprop, SGD]

# Training settings ....................................................................................................
Training:
  device: cpu
  batch_size: 1
  learning_rate: 0.001
  boundary_loss_weight: 1
  variational_loss_weight: 1
  write_time: True
